{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## GENERAL MARKING COMMENTS ARE FORMATTED IN RAW NBCONVERT\n",
    "\n",
    "- Gather all your libraries in one place. It's recommended that way because you'll never know if your reader has all     the libraries installed, and gathering them all at the top make this easier\n",
    "\n",
    "- Instead of using the top keywords derived from EDA, you could use the keywords generated from the model since the     model could generate insights that normal human won't usually be able to tell. From these findings from modelling,     create targeted insights and recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Project 3 - Book 2: Web APIs & Classification\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Nutrino is a leading provider of nutrition related data services and analytics. As part of the data science team, we have been tasked to generate business insights curated from popular social media platforms. The company will be able to use that information to better understand customers & markets, enhance decision-making, and ultimately increase profitability.\n",
    "\n",
    "To do so, we will first be scrapping data from reddit and using classification models such as Logistic Regression and Naive Bayes to uncover patterns within 2 popular diets, Keto and Vegan. In developing this proof of concept, we want to be able to classify all available text data into business ready data, stengthening our core analytics product. \n",
    "\n",
    "We also hope to reveal previously unrecognised sub-trends that pertains to attitudes, lifestyles and buying behavior. With a better understanding of the population and their eating patterns, we will be able to advise our clients oh how they can launch their targeted marketing campaigns and improve the success of their products and programs.\n",
    "\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "As the data science team in Nutrino, we have been tasked to build a classifier to improve core product of the company, which is to provide nutrition related data services and analytics. We are also tasked to identify patterns on 2 currently trending diets, keto and vegan. \n",
    "\n",
    "Our classifier was successful in predicting at an above 90% accuracy score. We also identified patterns in the motivations and preferences of the 2 groups of subredditors, which will help determine the kind of customer engagement with teach group. \n",
    "\n",
    "\n",
    "\n",
    "## Notebooks:\n",
    "- [Data Scrapping and Cleaning](./book1_data_scrapping_cleaning.ipynb)\n",
    "- [EDA](./book2_eda.ipynb)\n",
    "- [Modeling and Recommendations](./book3_preprocesing_modeling_recommendations.ipynb)\n",
    "\n",
    "\n",
    "## Contents:\n",
    "- [Import Libraries](#Import-Libraries)\n",
    "- [Import Data](#Import-Data)\n",
    "- [Baseline Accuracy](#Baseline-Accuracy)\n",
    "- [Model Prep](#Model-Prep)\n",
    "- [Model Selection](#Model-Selection)\n",
    "- [Modeling Test Data](#Modeling-Test-Data)\n",
    "- [Classification Metrics](#Classification-Metrics)\n",
    "- [Recommendations](#Recommendations)\n",
    "- [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1647, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>vegan_label</th>\n",
       "      <th>subred_name</th>\n",
       "      <th>author</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>post_id</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regan russell animal rights activist killed st...</td>\n",
       "      <td>1</td>\n",
       "      <td>r/vegan</td>\n",
       "      <td>nekkototoro</td>\n",
       "      <td>5371</td>\n",
       "      <td>583</td>\n",
       "      <td>hca93z</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vegan hacktivists looking developers ui design...</td>\n",
       "      <td>1</td>\n",
       "      <td>r/vegan</td>\n",
       "      <td>veganactivismbot</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>f3svif</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>last words fellow vegan elijah mcclain murdere...</td>\n",
       "      <td>1</td>\n",
       "      <td>r/vegan</td>\n",
       "      <td>VenmoMeFiveBucks</td>\n",
       "      <td>1430</td>\n",
       "      <td>147</td>\n",
       "      <td>hf6eej</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30 pounds vegan since may 3 never felt better</td>\n",
       "      <td>1</td>\n",
       "      <td>r/vegan</td>\n",
       "      <td>CoyoteaParty</td>\n",
       "      <td>1195</td>\n",
       "      <td>64</td>\n",
       "      <td>hf55ez</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mink fur farms shut netherlands due covid 19 o...</td>\n",
       "      <td>1</td>\n",
       "      <td>r/vegan</td>\n",
       "      <td>PlantPoweredAdam</td>\n",
       "      <td>2515</td>\n",
       "      <td>84</td>\n",
       "      <td>hezfns</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  vegan_label subred_name  \\\n",
       "0  regan russell animal rights activist killed st...            1     r/vegan   \n",
       "1  vegan hacktivists looking developers ui design...            1     r/vegan   \n",
       "2  last words fellow vegan elijah mcclain murdere...            1     r/vegan   \n",
       "3      30 pounds vegan since may 3 never felt better            1     r/vegan   \n",
       "4  mink fur farms shut netherlands due covid 19 o...            1     r/vegan   \n",
       "\n",
       "             author  upvotes  num_comments post_id  word_count  \n",
       "0       nekkototoro     5371           583  hca93z          19  \n",
       "1  veganactivismbot       70             0  f3svif         184  \n",
       "2  VenmoMeFiveBucks     1430           147  hf6eej          13  \n",
       "3      CoyoteaParty     1195            64  hf55ez           9  \n",
       "4  PlantPoweredAdam     2515            84  hezfns           9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text            0\n",
       "vegan_label     0\n",
       "subred_name     0\n",
       "author          0\n",
       "upvotes         0\n",
       "num_comments    0\n",
       "post_id         0\n",
       "word_count      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "#no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.584699\n",
       "0    0.415301\n",
       "Name: vegan_label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's calculate a baseline score so that we know if \n",
    "#our model is outperforming our null model\n",
    "\n",
    "df['vegan_label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of baseline accuracy\n",
    "The baseline accuracy means that if we predict 1 for all posts, we would be right at least 57% of the time. \n",
    "\n",
    "Now let's prepare for modelling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prep: Create feature matrix (`X`) and target vector (`y`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=df['text']\n",
    "y=df['vegan_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prep: Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=y)\n",
    "#here we stratify due to the unbalanced classes in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prep: Steps for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here we prepare the steps for pipeline\n",
    "cvec_lr = [('cvec', CountVectorizer()),('lr', LogisticRegression())]\n",
    "tvec_lr = [('tvec',TfidfVectorizer()),('lr', LogisticRegression())]\n",
    "cvec_nb = [('cvec', CountVectorizer()),('nb', MultinomialNB())]\n",
    "tvec_nb = [('tvec',TfidfVectorizer()),('nb', MultinomialNB())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choice of Model\n",
    "\n",
    "In order to select a model, we will be running 2 vectorizers and 2 models. \n",
    "The vectorizers are namely Count Vectorizer and TFIDF Vectorizer.\n",
    "Count Vectoriser counts the number of times a word appears. \n",
    "TFIDF goes a step further to apply a penalty for words that appear in  multiple posts. \n",
    "\n",
    "The models we chose are Logistic Regression and Naive Bayes (MultiNomial). \n",
    "\n",
    "Logistic Regression estimates the relationship between our features and the target variable by estimating probabilities using a sigmoid function.\n",
    "Naive bayes classifier is based on the bayes theorem which is in turn baed on conditional probabilities. It predicts probailities for each class and the class with the highest probability is ocnsidered the most likely class. \n",
    "\n",
    "We chose log reg because:\n",
    "- Y is binary\n",
    "- easy to interpret\n",
    "\n",
    "We chose NB because:\n",
    "- performs well with text classification\n",
    "- specifically the Multinomial because the columns of X are all integer counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: CountVectorizer and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prep: Pipe_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_1_params = {\n",
    "    'cvec__max_features': [1000, 1500, 2000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [0.8, 0.85, 0.9],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'lr__penalty': ['l1', 'l2'],\n",
    "    'lr__solver' : ['liblinear'],\n",
    "    'lr__C':[1,0.1,0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fit and Score: Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958997722095672\n",
      "{'cvec__max_df': 0.8, 'cvec__max_features': 1500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'lr__C': 0.1, 'lr__penalty': 'l2', 'lr__solver': 'liblinear'}\n",
      "CPU times: user 4min 39s, sys: 4.03 s, total: 4min 43s\n",
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#instantiate pipeline\n",
    "pipe_1 = Pipeline(cvec_lr)\n",
    "\n",
    "gs_1 = GridSearchCV(pipe_1,param_grid=pipe_1_params,cv=5)\n",
    "gs_1.fit(X_train,y_train)\n",
    "\n",
    "print(gs_1.best_score_)\n",
    "print(gs_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Tfidf Vectorizer and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prep: Pipe_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_2_params = {\n",
    "    'tvec__max_features': [2500, 3000, 3500],\n",
    "    'tvec__max_df': [0.3, 0.5, 0.7],\n",
    "    'tvec__sublinear_tf': [True, False],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'lr__penalty': ['l1', 'l2'],\n",
    "    'lr__solver' : ['liblinear'],\n",
    "    'lr__C':[1,0.1,0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fit and Score: Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9582384206529992\n",
      "{'lr__C': 1, 'lr__penalty': 'l2', 'lr__solver': 'liblinear', 'tvec__max_df': 0.5, 'tvec__max_features': 2500, 'tvec__ngram_range': (1, 1), 'tvec__sublinear_tf': False}\n",
      "CPU times: user 4min 39s, sys: 4.29 s, total: 4min 44s\n",
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#instantiate pipeline\n",
    "pipe_2 = Pipeline(tvec_lr)\n",
    "\n",
    "gs_2 = GridSearchCV(pipe_2,param_grid=pipe_2_params,cv=5)\n",
    "gs_2.fit(X_train,y_train)\n",
    "\n",
    "print(gs_2.best_score_)\n",
    "print(gs_2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: CountVectorizer and Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prep: Pipe_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_3_params = {\n",
    "    'cvec__max_features': [1000, 1500, 2000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [0.75, 0.8, 0.85],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'nb__alpha' : [1.0, 1.1, 1.2],\n",
    "    'nb__fit_prior' : [True, False]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fit and Score: Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9483675018982536\n",
      "{'cvec__max_df': 0.75, 'cvec__max_features': 2000, 'cvec__min_df': 3, 'cvec__ngram_range': (1, 1), 'nb__alpha': 1.0, 'nb__fit_prior': True}\n",
      "CPU times: user 4min 31s, sys: 4.19 s, total: 4min 35s\n",
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#instantiate pipeline\n",
    "pipe_3 = Pipeline(cvec_nb)\n",
    "\n",
    "gs_3 = GridSearchCV(pipe_3,param_grid=pipe_3_params,cv=5)\n",
    "gs_3.fit(X_train,y_train)\n",
    "\n",
    "print(gs_3.best_score_)\n",
    "print(gs_3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Tfidf Vectorizer and Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prep: Pipe_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_4_params = {\n",
    "    'tvec__max_features': [2500, 3000, 3500],\n",
    "    'tvec__max_df': [0.3, 0.5, 0.7],\n",
    "    'tvec__sublinear_tf': [True, False],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'nb__alpha' : [1.0, 1.1, 1.2],\n",
    "    'nb__fit_prior' : [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fit and Score: Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9453302961275627\n",
      "{'nb__alpha': 1.2, 'nb__fit_prior': True, 'tvec__max_df': 0.5, 'tvec__max_features': 2500, 'tvec__ngram_range': (1, 2), 'tvec__sublinear_tf': False}\n",
      "CPU times: user 4min 16s, sys: 3.33 s, total: 4min 20s\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#instantiate pipeline\n",
    "pipe_4 = Pipeline(tvec_nb)\n",
    "\n",
    "gs_4 = GridSearchCV(pipe_4,param_grid=pipe_4_params,cv=5)\n",
    "gs_4.fit(X_train,y_train)\n",
    "\n",
    "print(gs_4.best_score_)\n",
    "print(gs_4.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scores recap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVec and LR Score: 0.958997722095672\n",
      "TFIDFVec and LR Score: 0.9582384206529992\n",
      "CVec and NB Score: 0.9483675018982536\n",
      "TFIDFVec and NB Score: 0.9453302961275627\n"
     ]
    }
   ],
   "source": [
    "print(f'CVec and LR Score: {gs_1.best_score_}')\n",
    "print(f'TFIDFVec and LR Score: {gs_2.best_score_}')\n",
    "print(f'CVec and NB Score: {gs_3.best_score_}')\n",
    "print(f'TFIDFVec and NB Score: {gs_4.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation on train scores:\n",
    "Overall, all our scores are pretty similar and way above our baseline score of 0.571. The default score used by gridsearch is the accuracy score. Our accuracy scores range from 0.945 to 0.959. This means that our model is doing a pretty great job of classifying text from the 2 subreddits. \n",
    "\n",
    "##### Model Selection:\n",
    "Based on the cross validation scores from all 4 models, we will proceed with the Count Vectorizer and Logistic Regression combination, which gave us the highest train accuracy score of 0.959. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9636363636363636"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation of test scores\n",
    "Our test score exceeded our train score with 0.964, with some variance from the train score. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     features      coef\n",
      "1404    vegan  1.326415\n",
      "97     animal  0.433730\n",
      "    features      coef\n",
      "242    carbs -0.766565\n",
      "721     keto -1.775069\n"
     ]
    }
   ],
   "source": [
    "wd_features = gs_1.best_estimator_.named_steps['cvec'].get_feature_names()\n",
    "wd_coef = gs_1.best_estimator_.named_steps['lr'].coef_[0]\n",
    "\n",
    "coef_df = pd.DataFrame(zip(wd_features,wd_coef),columns=['features','coef']).sort_values('coef',ascending=False)\n",
    "\n",
    "print(coef_df.head(2))\n",
    "print(coef_df.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A positive coefficient points towards the vegan class while a negative coefficient points to the keto class. \n",
    "\n",
    "Besides the obvious words of vegan and keto, we can interpret the coefficient as follows:\n",
    "- animal -> As the word count for animal increases by 1, our classifier is e^0.434 = 1.54 times more likely to classify it as a vegan post\n",
    "- carbs ->  As the word count for carbs increases by 1, our classifier is e^0.766 = 2.15 times more likely to classify it as a vegan post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = gs_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 125\n",
      "False Positive (Type I): 12\n",
      "False Negative (Type II): 0\n",
      "True Positive: 193\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test,preds).ravel()\n",
    "print('True Negative:' ,tn)\n",
    "print('False Positive (Type I):' ,fp)\n",
    "print('False Negative (Type II):' ,fn)\n",
    "print('True Positive:' ,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9414634146341463\n"
     ]
    }
   ],
   "source": [
    "#Precision\n",
    "\n",
    "prec = tp/(tp+fp)\n",
    "\n",
    "print(f'Precision: {prec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "Precision measures primarily on type I errors or false positives. This means that the model classifies a post as a vegan post when it is actually a keto post.\n",
    "\n",
    "Our precision score is 0.94 and this means that our model rarely mislabels a keto post as a vegan post. \n",
    "\n",
    "The shortcoming of this is that it cannot measure false negatives, classifying keto posts as vegan posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Recall/Sensitivity\n",
    "\n",
    "sens = tp/(tp+fn)\n",
    "\n",
    "print(f'Sensitivity: {sens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall/Sensitivity\n",
    "Recall focuses on type II errors. A type II error means that the model classifies a post as a keto post when it is actually a vegan post.\n",
    "\n",
    "Our precision score is 1.0 and this means that our model never mislabels a vegan post as a keto post. \n",
    "\n",
    "Vice versa, the shortcoming of this metric is that it cannot measure false positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9562043795620438"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's take a look at ROC AUC Score yet another metric\n",
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC Score\n",
    "Our high ROC AUC score of 0.96 (close to 1) confirms that we have a good separation between our vegan and keto classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95       137\n",
      "          1       0.94      1.00      0.97       193\n",
      "\n",
      "avg / total       0.97      0.96      0.96       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score\n",
    "The F1 score shows the balance between precision and recall. It is calculated by 2(precision*recall)/(precision+recall).\n",
    "Our high F1 score of 0.96 shows that we have a good balance of both of the above. \n",
    "\n",
    "Ultimately, we measure our success on the F1 score which generally works well with unbalanced classes, which we have at 58/42. \n",
    "Also, we dont particularly value identifying either false positive or false negatives more, Accuracy and F1 scores should be sufficient to measure our success. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our reccomendations are: \n",
    "- further develop the classifier to continuously improve our core product of generating data analytics  \n",
    "\n",
    "With this proof of concept, we can invest further resources to develop the model to eventually classify all available data, to contribute to our core product of nutrition data related services.  \n",
    "\n",
    "- vegan insights: focus on educating the target market\n",
    "\n",
    "With vegan subredditors, we noticed that the users were highly discerning. Afterall, vegans have made a life changing commitment to the lifestlye to avoid meat and animal products. They are concerned with making the world a better place. In order to rally these users, frequently post about the science behind veganism, share insights on how they can contribute to reduce animal cruelty and keep them updated on the change that veganism is bringing.\n",
    "\n",
    "- keto insights: focus on building a strong community\n",
    "\n",
    "With keto subredditors, a common goal/motivation is weight loss. Build a community with these people, share progress, recipes and tips. Build a platform when people can freely share their thoughts and concerns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "There were 2 keys questions that we set out to answer in our problem statement:\n",
    "1. Can we build a classifier, with at least 90% accuracy, to sort text data from Keto and Vegan subreddits?\n",
    "2. Can we draw insights from these text data for targeted marketing?\n",
    "\n",
    "After data cleaning, feature engineering and EDA, we ran our text data through a couple of vectorizer-model combinations. We tuned the hyperparameters to generate the best scores. From there, we scored them on the training data, using the accuracy scores. We chose the model with the highest accuracy score and scored our optimal model with the test data. Finally, our classifier achieved a test score of 0.964, which means that it correctly classified text data 96.4% of the time.\n",
    "\n",
    "We also drew insights from the EDA and profiled our target market. We realised differences in motivations and preferences between the 2 groups. Our recommendations are tailored to each group with a focus on educating for the vegans and building a strong community for the keto crowd. \n",
    "\n",
    "With these, we will be able to provide better insights to our clients to help with their marketing campaigns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve our model, I believe that we could have included texts from the comment section which were not availabble via the API. We could perhaps explore using PRAW to scrap comments. \n",
    "\n",
    "We could also run sentiment analysis on the data to see which posts and comments were favoured by different users of the subreddits. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
